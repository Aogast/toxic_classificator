Классификатор токсичности в  диалоге
Сыров Артём Андреевич
Постановка задачи
Цель проекта - разработать модель, которая на сообщениящ из переписки будет опредеять, токсичны ли сообщения от собеседника, а так же тип токсичности
/агрессии. 
Данная технология будет внедрена в тг бот. Это позволит быстро пересылать друзьм/парам пересылать в него сообщения, чтобы доказать собеседнику/партнеру, что рационально и аргументировано диалог выходит из конструктивного русла и надо продолжить общение в более адекватном и мирном ключе.
Формат входных и выходных данных
На вход модели будет дана строчка - промпт совмещающая в себе часть диалога или отдельные сообщения, а на выходе будет получаться строчка - ответ модели в формате json где будут описаны токсичное ли сообщение, а так же лейблы присвоенные данному сообщению
Метрики
Так как основная задача для LLM будет бинарная классификация, то основной метрикой я буду брать f_1 score - как модель правильно определяет токсичность в сообщениях, надеясь получить ее значение больше 0.85 - Так как это больше LLM для которой возможно будет мало данных, а еще помимо этого у нее будут другие задачи как присвоить лейблы - тут так же f_1 score будет считаться но с меньшими ожиданиями по метрике - 0.7 так как не у всех  датасетов будут нужные данные и пока сложно прикинуть какие значение можно получить +  так как это LLM то дообучение у меня будет на основе LoRA, что порой работает не так хорошо как full fine-tune.
Валидация и тест
Я объединю все датасеты, и стратифицированно разобью его на тренировачную, тестовую и валидационную выбору(70%:15%:15%) с фиксированным seed. Кросс валидация не планируется из-за довольно большого тестового и валидационного датасета, а так же это довольно дорого делать для LLM.
Датасеты
Для обучение планируются браться следующие три датасета с платформы kaggle:
* Jigsaw Multilingual Toxic Comment Classification
* Russian Language Toxic Comments
Общий объем датасетов составит 240к семплов. Из которых будет взято скорее всего не больше 20-40к семлов на обучение, так как обучать LLM довольно дорого(даже LoRA)
Обычно такого объема данных хватает на sft модели, так что из проблем может стать только то, что в русскоязычном датасете нет лейблов, а синтетически их сделать нельзя, так что возможно от идеи лейблов придеться отказаться/не считать метрику по ним и не учитыватть их как в целом задачу, а больше как фичу/ убрать лейблы из проекта вовсе. Так же из проблем может как раз стать долгое обучение модели
Моделирование
Бейзлайн
Простейшее решение, с которым можно будет сравнить мое - это взять недообученный, а просто запромптченный квен такого же размера(или даже чуть больше) и сравнить насколько он хорошо решает ту же задачу.
Основная модель
За основу будет взята скорее всего модель Qwen3 1.7B или Qwen3 4B([a]Смотря что поместиться на мою карту). Обучаться она будет через LoRA(peft), чтобы влезла на небольшую карточку со стандартной функцикей потерь для LLM - CrossEntropyLoss для токенов
Внедрение
Модель будет внедрена в тг бот, где бекенд будет получать от пользователя сообщение, затем делать с данным сообщением запрос в модель и возвращать пользователю вердик. Сама модель будет инфериться через vllm сервер(скорее всего). Такое взаимодействие будет проще всего для пользователя. Для этого бекенду понадобаться отдельне библиотеки для поднятие бота. 
